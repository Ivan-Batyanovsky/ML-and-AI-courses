{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CallTime  LastContactMonth  PrevAttempts  DaysPassed  HHInsurance  \\\n",
      "0        70                 0             0          -1            1   \n",
      "1       185                 1             0          -1            1   \n",
      "2       340                 2             1         119            1   \n",
      "3       819                 1             0          -1            1   \n",
      "4       192                 2             0          -1            0   \n",
      "\n",
      "   NoOfContacts  CarInsurance  \n",
      "0             2             0  \n",
      "1             5             0  \n",
      "2             1             1  \n",
      "3             2             1  \n",
      "4             1             0  \n"
     ]
    }
   ],
   "source": [
    "orig_data = pd.read_csv(r\"datasets/Insurance/final_data.csv\")  # Loading data\n",
    "\n",
    "listOfX = [col for col in orig_data.columns if col not in [\"CarInsurance\", \"Id\"]]  # List of parameters\n",
    "\n",
    "orig_data = orig_data.reset_index(drop=True)\n",
    "orig_data = orig_data.drop([\"Id\"], axis=1)\n",
    "\n",
    "print(orig_data.head())\n",
    "inputData = orig_data[listOfX]  # Getting parameters\n",
    "outputData = orig_data[\"CarInsurance\"]  # Getting answers\n",
    "outputData.replace(0, -1, inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputData, outputData, random_state=228, test_size=0.2)  # Spliting data\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias_feature(a):\n",
    "    a_extended = np.zeros((a.shape[0],a.shape[1]+1))\n",
    "    a_extended[:,:-1] = a\n",
    "    a_extended[:,-1] = int(1)  \n",
    "    return a_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySVM(object):\n",
    "    \n",
    "    def __init__(self, etha=0.01, alpha=0.1, epochs=500):\n",
    "        self._epochs = epochs\n",
    "        self._etha = etha\n",
    "        self._alpha = alpha\n",
    "        self._w = None\n",
    "        self.history_w = []\n",
    "        self.train_errors = None\n",
    "        self.val_errors = None\n",
    "        self.train_loss = None\n",
    "        self.val_loss = None\n",
    "    \n",
    "    def soft_hinge_loss(self, x, y):\n",
    "        return max(0, 1 - y * (np.dot(self._w, x))) + self._alpha * (np.dot(self._w, self._w.T))\n",
    "    \n",
    "    def fit(self, X_tr, X_tt, y_tr, y_tt):\n",
    "        X_tr = add_bias_feature(X_tr)\n",
    "        X_tt = add_bias_feature(X_tt)\n",
    "        \n",
    "        self._w = np.zeros((1, X_tr.shape[1]))\n",
    "        self.history_w.append(self._w)\n",
    "        \n",
    "        train_errors = []\n",
    "        val_errors = []\n",
    "        train_loss_epoch = []\n",
    "        val_loss_epoch = []\n",
    "        \n",
    "        for epoch in range(self._epochs):\n",
    "            tr_err = 0\n",
    "            val_err = 0\n",
    "            tr_loss = 0\n",
    "            val_loss = 0\n",
    "            for x, y in zip(X_tr, y_tr):\n",
    "#                 print(i, x)\n",
    "                M = y * (np.dot(self._w, x))\n",
    "#                 print(self._w.shape, x.shape)  # w (1, 7) and x (7, 1)\n",
    "                if M >= 1:\n",
    "                    self._w -= self._etha * (self._alpha * self._w/self._epochs)\n",
    "                    tr_loss += self.soft_hinge_loss(x, y)\n",
    "                else:\n",
    "                    self._w -= self._etha * (self._alpha * self._w/self._epochs - y * x.T)\n",
    "                    tr_err += 1\n",
    "                    tr_loss += self.soft_hinge_loss(x, y)\n",
    "                self.history_w.append(self._w)\n",
    "            for x, y in zip(X_tt, y_tt):\n",
    "                val_loss += self.soft_hinge_loss(x, y)\n",
    "                val_err += (y * np.dot(self._w, x) < 1).astype(int)\n",
    "                \n",
    "            train_errors.append(tr_err)\n",
    "            val_errors.append(val_err)\n",
    "            train_loss_epoch.append(tr_loss)\n",
    "            val_loss_epoch.append(val_loss)\n",
    "        self.history_w = np.array(self.history_w)    \n",
    "        self.train_errors = np.array(train_errors)\n",
    "        self.val_errors = np.array(val_errors)\n",
    "        self.train_loss = np.array(train_loss_epoch)\n",
    "        self.val_loss = np.array(val_loss_epoch)\n",
    "\n",
    "    def predict(self, X:np.array) -> np.array:\n",
    "        y_pred = []\n",
    "        X = add_bias_feature(X)\n",
    "        for i in range(len(X)):\n",
    "            y_pred.append(np.sign(np.dot(self._w, X[i])))\n",
    "        return np.array(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = MySVM(etha=0.005, alpha=0.005, epochs=10000)\n",
    "sv.fit(X_train.to_numpy(), X_test.to_numpy(), y_train.to_numpy(), y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6064814814814815\n",
      "0.8534201954397395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7185863874345549"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = sv.predict(X_test.to_numpy())\n",
    "print(precision_score(y_test, preds))\n",
    "print(recall_score(y_test, preds))\n",
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7879581151832461\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "C = 0.05\n",
    "model1 = svm.LinearSVC(C=C, max_iter=10000)\n",
    "\n",
    "model1.fit(X_train, y_train)\n",
    "y_predict = model1.predict(X_test)\n",
    "print(accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
